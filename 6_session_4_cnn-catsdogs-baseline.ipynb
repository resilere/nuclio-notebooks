{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xULjVynfIMip"
   },
   "source": [
    "![Nuclio logo](https://nuclio.school/wp-content/uploads/2018/12/nucleoDS-newBlack.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kswWzeShIMiq"
   },
   "source": [
    "## 1. Get the Data\n",
    "\n",
    "You can find the data at this Google Drive URL (NPZ format)\n",
    "\n",
    "https://drive.google.com/file/d/1-OplAg9THXuzKC_oYAiB4wdBmCTdiy4z/view?usp=sharing <br>\n",
    "https://drive.google.com/file/d/1-Svi93L-C7qAq2oJmtajfCJDjGdJTIaE/view?usp=sharing <br>\n",
    "https://drive.google.com/file/d/1-Dpozh1KCEvuCYgYuaf98-PzHhHTo3F_/view?usp=sharing <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If working at colab, mount Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P12a4C2vzZL4"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIVsM2ZsIMiw"
   },
   "source": [
    "## 2. Libraries\n",
    "\n",
    "To begin, let's load those libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "tMmwJ-ZEoz3P"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tensorflow import keras as ks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LYPneYfoz3i"
   },
   "source": [
    "## 3. Defining some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1_noICIoz3j"
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=150\n",
    "IMAGE_HEIGHT=150\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3\n",
    "\n",
    "# We define the path where you have the NPZ files\n",
    "path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7335a579cc0268fba5d34d6f7558f33c187eedb3",
    "id": "ex_xAKguoz3n"
   },
   "source": [
    "## 4. We prepare the training data\n",
    "\n",
    "We will load them in the NPZ format that we discussed in the last class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "z-eYrcixoz3o"
   },
   "outputs": [],
   "source": [
    "dict_npz = np.load(path+'xy_train_img.npz')\n",
    "x_train_img = dict_npz['x']\n",
    "y_train_img = dict_npz['y']\n",
    "\n",
    "dict_npz = np.load(path+'xy_test_img.npz')\n",
    "x_test_img = dict_npz['x']\n",
    "y_test_img = dict_npz['y']\n",
    "\n",
    "dict_npz = np.load(path+'xy_val_img.npz')\n",
    "x_val_img = dict_npz['x']\n",
    "y_val_img = dict_npz['y']\n",
    "\n",
    "x_train_scaled = x_train_img / 255.\n",
    "x_test_scaled = x_test_img / 255.\n",
    "x_val_scaled = x_val_img / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "915bb9ba7063ab4d5c07c542419ae119003a5f98",
    "id": "owVl2D5Voz3s"
   },
   "outputs": [],
   "source": [
    "print(\"Shape X train:\", x_train_scaled.shape)\n",
    "print(\"Shape Y train:\", y_train_img.shape)\n",
    "\n",
    "print(\"Shape X test:\", x_test_scaled.shape)\n",
    "print(\"Shape Y test:\", y_test_img.shape)\n",
    "\n",
    "print(\"Shape X val:\", x_val_scaled.shape)\n",
    "print(\"Shape Y val:\", y_val_img.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a999484fc35b73373fafe2253ae9db7ff46fdb90",
    "id": "3eWnz7Uioz32"
   },
   "source": [
    "## 5. Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa26f0bc7a6d835a24989790b20f3c6f32946f45",
    "id": "xvjKCJDYoz32"
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(y_train_img, columns=['category'])\n",
    "df_train['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3a08da58107777a1dd05c4a4bf5c484484923cac",
    "id": "Hqzssxq7oz37"
   },
   "source": [
    "As we can see we have 2500 examples of each class ... a little to be a neural network for computer vision ... you will see ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "400a293df3c8499059d9175f3915187074efd971",
    "id": "3-gXqKRzoz38"
   },
   "source": [
    "## 6. Lets see an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "602b40f7353871cb161c60b5237f0da0096b2f47",
    "id": "2hwgI2aVoz39"
   },
   "outputs": [],
   "source": [
    "sample = random.choice(range(0,4999))\n",
    "image = x_train_scaled[sample]\n",
    "plt.imshow(image, cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b244e6b7715a04fc6df92dd6dfa3d35c473ca600",
    "id": "oCEFBfkWoz4B"
   },
   "source": [
    "## 7. Let's stack blocks to make the model\n",
    "\n",
    "<img src=\"https://i.imgur.com/ebkMGGu.jpg\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c9f833c1441b657c779844912d0b8028218d454",
    "id": "RwIlNswdoz4E"
   },
   "outputs": [],
   "source": [
    "model = ks.Sequential()\n",
    "\n",
    "model.add(ks.layers.Conv2D(16, (3, 3), activation='relu', \n",
    "                           input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "model.add(ks.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(ks.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(ks.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(ks.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(ks.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(ks.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(ks.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(ks.layers.Flatten())\n",
    "model.add(ks.layers.Dense(512, activation='relu'))\n",
    "model.add(ks.layers.Dropout(0.3))\n",
    "model.add(ks.layers.Dense(512, activation='relu'))\n",
    "model.add(ks.layers.Dropout(0.3))\n",
    "model.add(ks.layers.Dense(1, activation='sigmoid')) # 1 of output as the target is binary (0 or 1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUWzg0-hnesq"
   },
   "source": [
    "## 8. Let's compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3XFSpbcnd3M"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd496f6c65888a969be3703135b0b03a8a1190c8",
    "id": "FjqQRO0Voz4I"
   },
   "source": [
    "## 9. Let's define a callback for early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "76c9ba4fb7f930c96b2c3e0d6b68ed9fa6a4227b",
    "id": "kBF3ly91oz4P"
   },
   "source": [
    "**Early Stopping**\n",
    "\n",
    "We prevent overfitting by stopping when after 10 epochs and the validation error does not decrease (we are in a plateau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3421c5ec428da6c0d8cc1184179a9caff1e01d1c",
    "id": "tvAN5_48oz4Q"
   },
   "outputs": [],
   "source": [
    "callback_val_loss = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "callback_val_accuracy = EarlyStopping(monitor=\"val_accuracy\", patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YycSloTfoz4Z"
   },
   "source": [
    "## 10. Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIE5IV7voz4a"
   },
   "source": [
    "\n",
    "We will do a one-hot encoding that will be good for our classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpngtNKUxV3v"
   },
   "outputs": [],
   "source": [
    "y_train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9darYNr97B1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train_img)\n",
    "y_train_encoded = le.transform(y_train_img)\n",
    "y_val_encoded = le.transform(y_val_img)\n",
    "y_test_encoded = le.transform(y_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnqC3rm--O0o"
   },
   "outputs": [],
   "source": [
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff760be9104f7d9492467b8d9d3405011aa77d11",
    "id": "DmgPnBdWoz4u"
   },
   "source": [
    "## 11. Transformer from images to consumable data for the neural network\n",
    "\n",
    "**Train data**\n",
    "\n",
    "Here we will include our image generation part (with starting code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d1c7818703a8a4bac5c036fdea45972aa9e5e9e",
    "id": "Nlxz_DO7oz4v"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    )\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x_train_img,  # Here we need non-rescaled data\n",
    "    y_train_encoded, \n",
    "    batch_size=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "859c7b2857939c19fd2e3bb32839c9f7deb5aa3f",
    "id": "e7qjyLM-oz4y"
   },
   "source": [
    "**Validation (test does not need it)**\n",
    "\n",
    "Note that here the only modification is a rescaling, no modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7925e16bcacc89f4484fb6fe47e54d6420af732e",
    "id": "HpWcatHOoz4z"
   },
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    "    )\n",
    "validation_generator = validation_datagen.flow(\n",
    "    x_val_img, \n",
    "    y_val_encoded, \n",
    "    batch_size=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIEMYd471wV8"
   },
   "source": [
    "## 12. Let's see what the data generator looks like\n",
    "\n",
    "To fill in to see what the new image generator gives us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4v0izLCV1346"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5cd8df64e794ed17de326b613a9819e7da977a0e",
    "id": "cT4ohS-ioz4_"
   },
   "source": [
    "## 13. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0836a4cc8aa0abf603e0f96573c0c4ff383ad56b",
    "id": "xgh5rr0doz5A"
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "history = model.fit(x_train_scaled, y_train_encoded, epochs=epochs, \n",
    "                    validation_data=(x_val_scaled, y_val_encoded), batch_size=512, \n",
    "                    callbacks=[callback_val_loss, callback_val_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa1fbc4081ae0de2993188b2bf658a0be5bc0687",
    "id": "A6Uio2wgoz5D"
   },
   "source": [
    "## 14. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67575a4decdaf79a915d23151626b784ffa82642",
    "id": "Wv8k1cSeoz5E"
   },
   "outputs": [],
   "source": [
    "model.save(path+\"basic_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b76c0a9040bc0babf0a453e567e41e22f8a1e0e",
    "id": "7CWxAqsOoz5H"
   },
   "source": [
    "## 15. Let's see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79055f2dc3e2abb47bea758e0464c86ca42ab431",
    "id": "if5uxIKkoz5I"
   },
   "outputs": [],
   "source": [
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'], color='blue', label='train')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='validation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEtAd5Xwp1_y"
   },
   "outputs": [],
   "source": [
    "_, acc = model.evaluate(x_test_scaled, y_test_encoded, verbose=0)\n",
    "print('Test accuracy of the model without data augmentation -> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESmMskPQGElI"
   },
   "source": [
    "## 16. Lets see some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMmomkCZGElI"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_scaled) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZ0P2alCGElI"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    if true_label == 1:\n",
    "        true_label = 'dog'\n",
    "    else:\n",
    "        true_label = 'cat'\n",
    "\n",
    "    if np.max(predictions_array) > 0.50:\n",
    "        predicted_label = 'dog'\n",
    "    else:\n",
    "        predicted_label = 'cat'\n",
    "\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n",
    "                                100*np.max(predictions_array),\n",
    "                                true_label),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array, true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(1))\n",
    "    plt.yticks([])\n",
    "\n",
    "    if true_label == 1:\n",
    "        true_label = 'dog'\n",
    "    else:\n",
    "        true_label = 'cat'\n",
    "\n",
    "    if np.max(predictions_array) > 0.50:\n",
    "        predicted_label = 'dog'\n",
    "    else:\n",
    "        predicted_label = 'cat'\n",
    "\n",
    "    if predicted_label == true_label:\n",
    "        color_plt = 'blue'\n",
    "    else:\n",
    "        color_plt = 'red'\n",
    "\n",
    "    thisplot = plt.bar(range(1), np.max(predictions_array), color=color_plt)\n",
    "    plt.ylim([0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yPSHiwRGElI"
   },
   "source": [
    "We draw the first samples, with the predictions and their real values (a total of 20 images, so as not to abuse your laptops)\n",
    "\n",
    "We color the correct predictions in blue and the failures in red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qb08Ry3dGElJ"
   },
   "outputs": [],
   "source": [
    "num_rows = 5\n",
    "num_cols = 4\n",
    "start = 490\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i+start, predictions[i+start], y_test_encoded, x_test_scaled)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i+start, predictions[i+start], y_test_encoded)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cnn-dataaug-catsdogs-v0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
